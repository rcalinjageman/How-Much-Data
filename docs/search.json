[
  {
    "objectID": "Why You Need Sample-Size Planning.html",
    "href": "Why You Need Sample-Size Planning.html",
    "title": "Why You Need Sample-Size Planning",
    "section": "",
    "text": "Why is sample-size planning so important? The short video above takes you through some extrinsic reasons (funders demand it!) and some more important intrinsic reasons (it is an ethical obligation and a key to fruitful science!).\nWant to dig deeper? Here are some of the guidelines and reporting requirements mentioned:\n\nNIH emphasis on rigor and reproducibility\n\nAs of 2016, NIH has adopted a new initiative on Rigor and Reproducibility that stress evaluation of project proposals for their ability to produce robust and unbiased results.\nIn explaining this new policy, sample-size planning was listed as a way to help meet this new evaluation criterion. See the NIH blog post here:\n\nReporting Guidelines -\n\nThe ARRIVE guidelines provide very useful advice for reporting in vivo experiments. It includes the requirement of reporting sample sizes clearly and justifying how they were set.\nThe NIH also helped organize a set of principles for the reporting of pre-clinical research; these guidelines were endorsed by a wide variety of journals and professional societies. Here are the NIH guidelines. The guidelines related to transparency stipulates that authors should explain their sample-size determinations.\n\nNature Neuroscience announced updated standards in 2013 editorial and released a reporting checklist authors should complete on submission that requires sample-size planning.\nJournal of Neuroscience has issued updated author guidelines as of March of 2017 that asks for sample-size justification.\n\n\nEthical considerations - the American Stasitical Association has put forth ethical guidelines for those who regularly use statistics. These enjoin statisticians to collect neither too much nor too little data (as both are ethically problematic). The guidelines are online here.",
    "crumbs": [
      "Course",
      "Why You Need Sample-Size Planning"
    ]
  },
  {
    "objectID": "webexercises.html",
    "href": "webexercises.html",
    "title": "Webexercises",
    "section": "",
    "text": "This is a Web Exercise template created by the psychology teaching team at the University of Glasgow, based on ideas from Software Carpentry. This template shows how instructors can easily create interactive web documents that students can use in self-guided learning.\nThe {webexercises} package provides a number of functions that you use in inline R code or through code chunk options to create HTML widgets (text boxes, pull down menus, buttons that reveal hidden content). Examples are given below. Render this file to HTML to see how it works.\nNOTE: To use the widgets in the compiled HTML file, you need to have a JavaScript-enabled browser."
  },
  {
    "objectID": "webexercises.html#example-questions",
    "href": "webexercises.html#example-questions",
    "title": "Webexercises",
    "section": "Example Questions",
    "text": "Example Questions\n\nFill-In-The-Blanks (fitb())\nCreate fill-in-the-blank questions using fitb(), providing the answer as the first argument.\n\n2 + 2 is \n\nYou can also create these questions dynamically, using variables from your R session.\n\nThe square root of 25 is: \n\nThe blanks are case-sensitive; if you don’t care about case, use the argument ignore_case = TRUE.\n\nWhat is the letter after D? \n\nIf you want to ignore differences in whitespace use, use the argument ignore_ws = TRUE (which is the default) and include spaces in your answer anywhere they could be acceptable.\n\nHow do you load the tidyverse package? \n\nYou can set more than one possible correct answer by setting the answers as a vector.\n\nType a vowel: \n\nYou can use regular expressions to test answers against more complex rules.\n\nType any 3 letters: \n\n\n\nMultiple Choice (mcq())\n\n“Never gonna give you up, never gonna: let you goturn you downrun awaylet you down”\n“I bless the rainsguess it rainssense the rain down in Africa” -Toto\n\n\n\nTrue or False (torf())\n\nTrue or False? You can permute values in a vector using sample(). TRUEFALSE\n\n\n\nLonger MCQs (longmcq())\nWhen your answers are very long, sometimes a drop-down select box gets formatted oddly. You can use longmcq() to deal with this. Since the answers are long, It’s probably best to set up the options inside an R chunk with echo=FALSE.\nWhat is a p-value?\n\n the probability that the null hypothesis is true the probability of the observed, or more extreme, data, under the assumption that the null-hypothesis is true the probability of making an error in your conclusion\n\nWhat is true about a 95% confidence interval of the mean?\n\n 95% of the data fall within this range if you repeated the process many times, 95% of intervals calculated in this way contain the true mean there is a 95% probability that the true mean lies within this range"
  },
  {
    "objectID": "webexercises.html#checked-sections",
    "href": "webexercises.html#checked-sections",
    "title": "Webexercises",
    "section": "Checked sections",
    "text": "Checked sections\nCreate sections with the class webex-check to add a button that hides feedback until it is pressed. Add the class webex-box to draw a box around the section (or use your own styles).\n\nI am going to learn a lot: TRUEFALSE\nWhat is a p-value?\n\n the probability that the null hypothesis is true the probability of the observed, or more extreme, data, under the assumption that the null-hypothesis is true the probability of making an error in your conclusion"
  },
  {
    "objectID": "webexercises.html#hidden-solutions-and-hints",
    "href": "webexercises.html#hidden-solutions-and-hints",
    "title": "Webexercises",
    "section": "Hidden solutions and hints",
    "text": "Hidden solutions and hints\nYou can fence off a solution area that will be hidden behind a button using hide() before the solution and unhide() after, each as inline R code. Pass the text you want to appear on the button to the hide() function.\nIf the solution is a code chunk, instead of using hide() and unhide(), simply set the webex.hide chunk option to TRUE, or set it to the string you wish to display on the button.\nRecreate the scatterplot below, using the built-in cars dataset.\n\n\n\n\n\n\n\n\n\n\n\nI need a hint\n\nSee the documentation for plot() (?plot)\n\n\n\n\n\nClick here to see the solution\n\nplot(cars$speed, cars$dist)"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To How Much Data",
    "section": "",
    "text": "This is the first post to the How Much Data blog! More to come!"
  },
  {
    "objectID": "Planning for Precision.html",
    "href": "Planning for Precision.html",
    "title": "Planning for Precision",
    "section": "",
    "text": "Planning for Precision",
    "crumbs": [
      "Course",
      "Three Approaches",
      "Planning for Precision"
    ]
  },
  {
    "objectID": "Planning for Evidence.html",
    "href": "Planning for Evidence.html",
    "title": "Planning for Evidence",
    "section": "",
    "text": "Bayesian statistics offers a very different path for sample-size determination: Planning for evidence.\nOne especially compelling version of this approach is called open-ended Sequential Bayes Factor (SBF) design, in which the researcher collects data until compelling evidence emerges for their hypothesis or the null.\nDespite the best-laid plans, a module on planning for evidence is not ready for release yet. Please stay tuned. In the meantime, the most authoritative and accessible resources for this approach is (Schönbrodt and Wagenmakers 2017).\n\n\n\n\nReferences\n\nSchönbrodt, Felix D., and Eric-Jan Wagenmakers. 2017. “Bayes Factor Design Analysis: Planning for Compelling Evidence.” Psychonomic Bulletin & Review, 1–16. https://doi.org/10.3758/s13423-017-1230-y.",
    "crumbs": [
      "Course",
      "Three Approaches",
      "Planning for Evidence"
    ]
  },
  {
    "objectID": "LICENSE-CC-BY-NC-4.0.html",
    "href": "LICENSE-CC-BY-NC-4.0.html",
    "title": "Attribution-NonCommercial 4.0 International",
    "section": "",
    "text": "The How Much Data website, videos, and resources are provided through a Creative Commons Attribution-NonCommercial License (see below). You may share (mirror) and adapt (borrow and alter) any/all course content, provided you credit the source and that you do not use these materials or your adaptations for commercial purposes."
  },
  {
    "objectID": "LICENSE-CC-BY-NC-4.0.html#creative-commons-attribution-noncommercial-4.0-international-public-license",
    "href": "LICENSE-CC-BY-NC-4.0.html#creative-commons-attribution-noncommercial-4.0-international-public-license",
    "title": "Attribution-NonCommercial 4.0 International",
    "section": "Creative Commons Attribution-NonCommercial 4.0 International Public License",
    "text": "Creative Commons Attribution-NonCommercial 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-NonCommercial 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 – Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nNonCommercial means not primarily intended for or directed towards commercial advantage or monetary compensation. For purposes of this Public License, the exchange of the Licensed Material for other material subject to Copyright and Similar Rights by digital file-sharing or similar means is NonCommercial provided there is no payment of monetary compensation in connection with the exchange.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 – Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part, for NonCommercial purposes only; and\nB. produce, reproduce, and Share Adapted Material for NonCommercial purposes only.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties, including when the Licensed Material is used other than for NonCommercial purposes.\n\n\n\n\nSection 3 – License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\nIf You Share Adapted Material You produce, the Adapter’s License You apply must not prevent recipients of the Adapted Material from complying with this Public License.\n\n\n\n\nSection 4 – Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database for NonCommercial purposes only;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material; and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 – Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 – Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 – Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 – Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to How Much Data?",
    "section": "",
    "text": "Welcome to How Much Data?, an online workshop on sample-size determination.\nHere you will find:\n\nA self-paced course to help you gain skills with sample-size planning\nA list of resources for helping you on your sample-size planning journey\nA blog with updates and news relevant for sample-size planning\nThe source code for this course and website that you may use to help customize these resources for your own training purposes and programs.\n\nThis course was developed by Bob Calin-Jageman at Dominican University. Your feedback, comments, and bug reports are very welcome – submit them via Github here.\nThis course has been a long time in the making and is still under active development. Expect addition of new topics (e.g. Simulation for Sample-Size Planning), additional simulations, and more.\nThe development of this course was supported by the NIGMS division of the National Institute of Health through grant 5R25GM132784-02. You can find other training modules focused on Rigor and Reproducibility here: https://www.nigms.nih.gov/training/pages/clearinghouse-for-training-modules-to-enhance-data-reproducibility.aspx"
  },
  {
    "objectID": "Decreasing Sample-Size Needs.html",
    "href": "Decreasing Sample-Size Needs.html",
    "title": "Decreasing Sample-Size Needs",
    "section": "",
    "text": "When you get serious about sample-size planning, you can often find that it takes much larger samples than you’d like to get clear answers to your scientific questions. While there is no doubt that many fields have settled on demonstrably inadequate sample sizes, the answer doesn’t have to be solely focused on collecting more data: we can also design better studies!\nThe video above gives an example of optimization - the art of coaxing more out of your data. There are three basic approaches:",
    "crumbs": [
      "Course",
      "Decreasing Sample-Size Needs"
    ]
  },
  {
    "objectID": "Decreasing Sample-Size Needs.html#reducing-variation-is-gold",
    "href": "Decreasing Sample-Size Needs.html#reducing-variation-is-gold",
    "title": "Decreasing Sample-Size Needs",
    "section": "Reducing Variation is Gold",
    "text": "Reducing Variation is Gold\nImagine you are characterizing neurogenesis in animals raised in stressed vs. standard conditions. From prevous studies, you know expect control animals to have about 3500 new neurons labelled 1 hour after BRDU injection, with a standard deviation of 500. You expect stress to have a pretty notable effect, say a 20% reduction to 2,800 labelled neurons, a difference of 3,500 - 2,800 = 700 neurons. This example is inspired by (Mirescu, Peters, and Gould 2004) (note that we’ll analyze this scenario with t-tests, as the original authors did, even though count data is typically not normally distributed and therefore not suitable for analysis in this way).\nLet’s say the typical study in your field uses n = 6/group. Is that adequate? Let’s find out with statpsych:\nWhat’s alpha = 0.05, what sample size do you need for 90% power? Let’s find out with statpsych:\n\nif (!require(\"statpsych\")) install.packages(\"statpsych\")\n\nLoading required package: statpsych\n\n# Estimate power for a 2-group design\nstatpsych::power.mean2(\n  alpha = 0.05,\n  n1 = 6,\n  n2 = 6,\n  var1 = 500^2,\n  var2 = 500^2,\n  es = 3500-2800\n)\n\n     Power\n 0.5906058\n\n\nUh oh, power is only 60%. That means we have a high risk of missing true effects and that statistically significant effects are likely to be inflated (see What Not To Do).\nWe could throw more data at the problem. But first, what would happen if we could reduce our sampling variability? Imagine, for example, that we might better-standardize our cell counts, perhaps by having two trainees count them independently and use the average. We could also refine what to do with borderline cases, and maybe standardize our injection and dissection protocols a little better. Suppose through these steps we could reduce within-group variation by just 20%. What would that do to our power?\n\nif (!require(\"statpsych\")) install.packages(\"statpsych\")\n\n# Same scenario, within group sd reduced by 20% through optimization\nstatpsych::power.mean2(\n  alpha = 0.05,\n  n1 = 6,\n  n2 = 6,\n  var1 = (500 * .8) ^2,   # Imagine reducing the sd to 80% of what your lab typically obtains\n  var2 = (500 * .8) ^2,   # same reduction in both groups\n  es = 3500-2800\n)\n\n     Power\n 0.7797131\n\n\nThat’s a big jump in power! We’re now getting close to a reasonable power with the same number of samples.\n\nWould a 20% increase in sample size have the same impact?\n\nif (!require(\"statpsych\")) install.packages(\"statpsych\")\n\n# Same scenario but increase sample-size by 20%... not the same impact!\nstatpsych::power.mean2(\n  alpha = 0.05,\n  n1 = 6 * 1.2,\n  n2 = 6 * 1.2,\n  var1 = 500^2,\n  var2 = 500^2,\n  es = 3500-2800\n)\n\n     Power\n 0.6868732\n\n\nNo! Why not? Well, recall that formula for the standard error of the mean:\n\\[\nsigma_{M} = frac{sigma}{sqrt(N)}\n\\]\nThis shows us that changes in within-group variation is directly related to expected sampling error, whiles sample-size is only related by its square root. That means that reducing noise (when possible) can be much more impactful than increasing sample size. If takes a 56% increase in sample-size to obtain the same benefit of a 20% reduction in within-group standard deviation!\n\nif (!require(\"statpsych\")) install.packages(\"statpsych\")\n\n# To get the same impact through sample-size, we need ~50% increase\nstatpsych::power.mean2(\n  alpha = 0.05,\n  n1 = 6 * 1.5,\n  n2 = 6 * 1.5,\n  var1 = 500^2,\n  var2 = 500^2,\n  es = 3500-2800\n)\n\n   Power\n 0.79613",
    "crumbs": [
      "Course",
      "Decreasing Sample-Size Needs"
    ]
  },
  {
    "objectID": "Decreasing Sample-Size Needs.html#more-gold-optimizing-for-larger-effects",
    "href": "Decreasing Sample-Size Needs.html#more-gold-optimizing-for-larger-effects",
    "title": "Decreasing Sample-Size Needs",
    "section": "More Gold: Optimizing for Larger Effects",
    "text": "More Gold: Optimizing for Larger Effects\nIn addition to reducing noise, we can work on maximizing signal. We might extend our treatement (longer stress), increase the magnitude of treatment (stronger stress), and/or focus in on measures which are especially susceptible to the treatment. For example, we might find that only some layers of the hippocampus undergo significant neurogenesis. If we could restrict our labelling to these layers, we could avoid having our effect diluted by unaffected measures.\nAs with reducing noise, increasing signal gets us a lot more bang for the buck. Let’s continue the previous example (2-group design, 6 per group, reduction of neurogenesis by 700 neurons, within-group standard deviaiton of 500 neurons).\nAgain, here is our ‘standard scenario’, in which we learn we have an inadequate sample size:\n\nif (!require(\"statpsych\")) install.packages(\"statpsych\")\n\n# Estimate power for a 2-group design\nstatpsych::power.mean2(\n  alpha = 0.05,\n  n1 = 6,\n  n2 = 6,\n  var1 = 500^2,\n  var2 = 500^2,\n  es = 3500-2800\n)\n\n     Power\n 0.5906058\n\n\nAnd now let’s check our power if we can increase the effect size by just 20%\n\nif (!require(\"statpsych\")) install.packages(\"statpsych\")\n\n# Estimate power for a 2-group design\nstatpsych::power.mean2(\n  alpha = 0.05,\n  n1 = 6,\n  n2 = 6,\n  var1 = 500^2,\n  var2 = 500^2,\n  es = (3500-2800) * 1.2   # increase effect size\n)\n\n     Power\n 0.7463204\n\n\nWow! We’ve get to nearly reasonable power without needing more resources.\nCertainly there are limits to what optimization can do, but working diligently to increase signal and decrease noise can help you get clearer answers with the same resources! That’s the type of thing that can make a huge difference over the course of your career.",
    "crumbs": [
      "Course",
      "Decreasing Sample-Size Needs"
    ]
  },
  {
    "objectID": "Decreasing Sample-Size Needs.html#design-matters-too",
    "href": "Decreasing Sample-Size Needs.html#design-matters-too",
    "title": "Decreasing Sample-Size Needs",
    "section": "Design Matters, Too",
    "text": "Design Matters, Too\nOur experimental design can also influence the efficiency of our experiment. In general, the simple two-group design is the least efficient design. Within-subjects designs typically have much more bang for the buck.\nLet’s take a look at the benefits, this time using an precision approach. Here we’ll use statpsych to simulate converting a between-subjects study to within-subjects. For each set of simulations we’ll focus on the typical confidence interval width.\nFirst, the between-subjects scenario. We’ll again work with 6 animals per group. We’ll assume the groups have equal variation (sd.ratio = 1) and that both come from normal distributions (dist1 = 1; dist2 = 1; where 1 tells statpsych to simulate draws from a normal distribution). We’ll conduct 1000 studies and report the average 95% confidence-interval width in standard deviation units:\n\nif (!require(\"statpsych\")) install.packages(\"statpsych\")\n\n# Base scenario - 6 animals/group, between subjects, equal variance\nstatpsych::sim.ci.mean2(\n  alpha = 0.05,\n  n1 = 6,\n  n2 = 6,\n  sd.ratio = 1,\n  dist1 = 1,\n  dist2 = 1,\n  rep = 1000\n)\n\n                             Coverage Lower Error Upper Error Ave CI Width\nEqual Variances Assumed:        0.957       0.019       0.024     2.502824\nEqual Variances Not Assumed:    0.959       0.017       0.024     2.563302\n\n\nWow! Our typical confidence interval will be ~2.5 standard deviations wide! That’s a lot of uncertainty, showing that our sample-size is appropriate only for assays in which we are justified in expecting truly massive effects.\nWhat if we ran the same study as a within-subject design? We’ll keep everything the same, but will also specifiy the correlation between pre/post measures. We’ll use 0.70, which is a reasonable estimate for a measure that has reasonable reliability.\nWhile within-subjects designs may not be feasible for studies in which the measurement requires destruction of the sample, matched-control designs can offer some of the same benefits.\n\nif (!require(\"statpsych\")) install.packages(\"statpsych\")\n\n# Switch to within-subjects, just n = 6, correlation of .7 between repeated measures\nstatpsych::sim.ci.mean.ps(\n  alpha = 0.05,\n  n = 6,\n  sd.ratio = 1,\n  cor = 0.7,\n  dist1 = 1,\n  dist2 = 1,\n  rep = 1000\n)\n\n Coverage Lower Error Upper Error Ave CI Width\n    0.941        0.03       0.029     1.557708\n\n\nHoly cow! We are now using 1/2 the animals (1 group of 6 rather than 2 groups of 6), but our confidence interval is now much reduced, to about 1.5 standard deviations in length. That’s still quite long, and only acceptable for assays where we expect pretty large effects… but much despite using 1/2 the resources. And what if we kept with 12 animals, but all in the within-subjects design?\n\nif (!require(\"statpsych\")) install.packages(\"statpsych\")\n\n# Switch to within-subjects, n = 12\nstatpsych::sim.ci.mean.ps(\n  alpha = 0.05,\n  n = 12,\n  sd.ratio = 1,\n  cor = 0.7,\n  dist1 = 1,\n  dist2 = 1,\n  rep = 1000\n)\n\n Coverage Lower Error Upper Error Ave CI Width\n    0.951       0.028       0.021    0.9626794\n\n\nNice - we’ve got our precision down to ~1 standard deviation without increasing our sample-size. Of course, we need to think critically about if a control/untreated design is needed – but we might be able to show no effect in control once and leverage that finding for repeated mechanistic studies with within-subjects designs–getting a lot more out of each experiment without much more in resources!\nFor many studies, within-subjects measurement is simply not feasible. With neurogenesis, for example, counting new neurons requires sacrificing the animal subjects, so additional measures are no longer feasible. In those cases, though, matched control designs and/or rigorous selection of covariates can provide many of the same benefits. For example, we could conduct a matched-control design by pre-testing stress-reactivity in all animals prior to the stress manipulation, making matched pairs of similar reactivity, and conducting random assignment to treatment within each pair. Depending on how linked scores are across match pairs, we can obtain many of the same benefits of a within-subjects design.",
    "crumbs": [
      "Course",
      "Decreasing Sample-Size Needs"
    ]
  },
  {
    "objectID": "Decreasing Sample-Size Needs.html#further-resources",
    "href": "Decreasing Sample-Size Needs.html#further-resources",
    "title": "Decreasing Sample-Size Needs",
    "section": "Further Resources",
    "text": "Further Resources\nIt’s surprisingly difficult to find good practical advice on optimization. Here are some papers I’ve found helpful:\n\nWritten for marking and consumer researchers, this paper nevertheless has vital tips for maximizing effect size (Meyvis and Van Osselaer 2018).\nFocused on animal research, this paper explains the 3R principles and how you can maximize the information you gain from each study (Lazic 2018).\nHere’s a primer focused on clinical trials, but again with lots of good advice that is broadly applicable (Kraemer 1991)\nA blog post from the OSF with good advice (MacKinnon 2013)\nA broader focus on reducing waste in research (Ioannidis et al. 2014)\nAnd finally, a blog post from Andrew Gelman that has some great advice (“Here Are Some Ways of Making Your Study Replicable. (No, the First Steps Are Not Preregistration or Increasing the Sample Size!),” n.d.)",
    "crumbs": [
      "Course",
      "Decreasing Sample-Size Needs"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "myblog",
    "section": "",
    "text": "statpsych for Sample-Size Planning\n\n\n\n\n\n\nnews\n\n\ntools\n\n\n\n\n\n\n\n\n\nOct 20, 2024\n\n\nBob Calin-Jageman\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To How Much Data\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nOct 1, 2024\n\n\nBob Calin-Jageman\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Effect Sizes.html",
    "href": "Effect Sizes.html",
    "title": "Effect Sizes",
    "section": "",
    "text": "What is an effect size?",
    "crumbs": [
      "Course",
      "Effect Sizes"
    ]
  },
  {
    "objectID": "Introduction.html",
    "href": "Introduction.html",
    "title": "An Introduction to How Much Data",
    "section": "",
    "text": "The topic of this course is sample-size planning: How do you know how much data to collect for a research project? \nStrangely, this is not often a point of emphasis in our scientific training. It is common for even advanced graduate courses in statistics to omit this topic or touch on it rarely. Even worse, the informal training you might receive in a lab is often wrong.\nThe lack of strong training on sample-size determination in science is worrisome. You wouldn’t get into a plane with a pilot who didn’t have a flight plan. So it seems a bit strange that often we charge off into experimentation with no real sense of where we are going and when it will end. That’s a missed opportunity, because with just a bit of initial planning we can do research that is more fruitful and reproducible. \nThe goal of this workshop is to dymystify sample-size planning and to provide actionable, practical advice about how to develop solid sample-size plans for your research. This course was developed not by a professional statistician but by a neuroscientist who accidentally fell down the rabbit hole of caring deeply about statistical inference. Thus, the course hopes to present material clearly, in language fellow bench-scientists can understand without having to delve too deeply into statistical arcana.   \nHere’s the outline of the course:\n\nFirst, we’ll discuss why sample-size planning is so vital to good science and therefore why it is worth investing your time and energy into completing this workshop. You may have been driven to this class because of some external mandate imposed by a funder or training program. The goal for this section is to help develop your own, intrinsic motivation for learning how to plan sample sizes.\nNext, we need to clear some very common but very bad practices: we’ll discuss the perils of “run-and-check” and of just copying forward sample-sizes from previous studies. It turns out these informal approaches to sample-size determination undermine sound science.\nThe unit on effect sizes provides some of the foundational knowledge needed to understand sample-size planning. Specifically, we define effect sizes, discuss how they can be expressed in different units, and provide some tips on how to build “effect size zoos” and start thinking in effect sizes.\nFinally, we get to the actual nitty-gritty of sample-size planning, covering three major approaches:\n\nPlanning for Power\nPlanning for Precision\nPlanning for Evidence (still under development)\n\nWith an understanding of some of the different approaches to sample-size planning, we’re ready for a check-list for a quality sample-size plan and to review some model plans.\nLast but not least, this workshop describes some important strategies for dealing with sample-size sticker shock. There are lots of ways to optimize your experiments to help reduce your sample-size needs and get more information out of your experiments.\n\nHope you enjoy this workshop. Please submit questions or bug reports to the GitHub page for this course: https://github.com/rcalinjageman/How-Much-Data/discussions.\nThe development of this course was supported by the NIGMS division of the National Institute of Health through grant 5R25GM132784-02. You can find other training modules focused on Rigor and Reproducibility here: https://www.nigms.nih.gov/training/pages/clearinghouse-for-training-modules-to-enhance-data-reproducibility.aspx.",
    "crumbs": [
      "Course",
      "Introduction"
    ]
  },
  {
    "objectID": "Model Sample-Size Plans.html",
    "href": "Model Sample-Size Plans.html",
    "title": "Model Sample-Size Plans",
    "section": "",
    "text": "The video above walks through model sample size plans when planning for power and for precision.\nIf this workshop helps inform your own sample-size plan, please share it with our community! Submit your sample size plans to the GitHub discussion page for this course, here: https://github.com/rcalinjageman/How-Much-Data/discussions. When you do, please indicated if you are willing for your sample-size plan to be linked/featured/discussed from this page as well.\nWhile working on your sample-size plan,it can also be helpful to reflect on what not to do. You may find this commentary on sample-size reporting in Nature Neuroscience useful (Goodhill 2017). Sadly, Nature Neuroscience did not seem to feel it was worth alerting its readers to these issues.\n\n\n\n\nReferences\n\nGoodhill, Geoffrey J. 2017. “Is Neuroscience Facing up to Statistical Power?” arXiv Preprint, January, 1–5. http://arxiv.org/abs/1701.01219.",
    "crumbs": [
      "Course",
      "Model Sample-Size Plans"
    ]
  },
  {
    "objectID": "Planning for Power.html",
    "href": "Planning for Power.html",
    "title": "Planning for Power",
    "section": "",
    "text": "The video above gives a quick overview of planning for power. Once you’ve viewed it, this page helps you dig into some details.",
    "crumbs": [
      "Course",
      "Three Approaches",
      "Planning for Power"
    ]
  },
  {
    "objectID": "Planning for Power.html#the-inputs-you-need-for-planning-for-power",
    "href": "Planning for Power.html#the-inputs-you-need-for-planning-for-power",
    "title": "Planning for Power",
    "section": "The Inputs You Need for Planning for Power",
    "text": "The Inputs You Need for Planning for Power\nSuppose you are in a lab that studies neurogenesis. You believe that early-life stress impairs neurogenesis. You will test your theory by exposing lab mice to stress or to standard living conditions. You will then use BRDU to label new neurons in the hippocampus. How can you make a good sampling plan for your study? (This example is inspired by (Mirescu, Peters, and Gould 2004)).\nTo start, you’ll need some inputs. Specifically, you need to know:\n\nThe stringency of your hypothesis test you will conduct (alpha = .05 is typical)\nThe level of power you want (80%? 90%? 95%?). The lower the power the lower your sample-size need. But the lower the power, the higher your chance of missing an effect if it is there. Just as bad, low-power samples that yield significant results often do so by inflating the true effect (see What Not to Do)\nYou also need to know the exact type of test you want to use. Will you use a t-test to compare means with the assumption of equal variance? Or, do you want to use a t-test to compare means without assuming equal variance (often called a Welch’s t-test)? Or, because you are dealing with count data, do you want to compare medians using a non-parametric test (e.g. the Mann-Whitny U test).\nYou also need a predicted effect: By how much do you believe stress will impact neurogenesis?\n\nIdeally you would have a prediction in raw units. Meaning, for example, you have a good sense of the typical level of neurogenesis under control conditions and you have a prediction of how much less neurogenesis you expect with stress (500 less neurons? 700 less neurons?). Ideally, this prediction is directional (predicting either a decrease or an increase over controls). You can, however, make a non-directional prediction (a change of at least 500 neurons)… though if you don’t know the direction, it’s hard to imagine the prediction being very well-founded.\n\nIf you go this route (which is best), you also need to provide a good estimate of the standard deviation in both groups.\n\nYou could also make your prediction in standard deviation units (1 standard deviation reduction, 2 standard deviation reduction, etc.).\n\nIf you go this route, you don’t need a predicted standard deviation for each group. That sounds attractive – you can get by with less guesswork. But on the other hand, what’s the basis of your prediction? If it is a well-founded prediction, it would usually come from familiarity with the assay and some knowledge of both typical scores and their variety. If you don’t know anything about the variety to expect in your assay, it’s hard to imagine your prediction in standard deviation units will be that informed.\n\n\n\nWhen asked for these inputs, many researchers become frustrated: How am I supposed to know all this before I do the study!? It’s true the inputs required for planning for power are extensive. But that’s because we plan for power to conduct a hypothesis test, and a hypothesis test is meant to test a hypothesis. If you don’t have a clear, quantitative hypothesis, then you aren’t really ready to conduct a hypothesis test, and if you’re not ready for a hypothesis test, you will definitely have difficulty planing one!\nSo: if you find the inputs for planning for power daunting you may want to consider: Am I ready to conduct a hypothesis test? Perhaps you want to start with some descriptive research to accurately characterize the system you are studying. In that case, you might want to plan for precision (for accurate description), and then, once you’ve described the system well you might formulate clear hypotheses that are worth testing.\nThis warning that you may not be ready for a hypothesis test may sound absurd. Just look at any journal and you’ll see hypothesis test after hypothesis test… clearly those researchers didn’t always have clear quantitative hypotheses and all this background knowledge. True – current norms are to use hypothesis tests willy nilly, in circumstances where the researcher has no clear hypotheses and little forethought. The regularity with which hypothesis testing is abused, however, does not make it wise, sensible, or sound. You can find more details on why hypothesis testing should be reserved for testing hypotheses in these sources (Calin-Jageman 2022; Scheel et al. 2020).",
    "crumbs": [
      "Course",
      "Three Approaches",
      "Planning for Power"
    ]
  },
  {
    "objectID": "Planning for Power.html#planning-for-power-with-statpsych",
    "href": "Planning for Power.html#planning-for-power-with-statpsych",
    "title": "Planning for Power",
    "section": "Planning for Power with statpsych",
    "text": "Planning for Power with statpsych\nWhat if you really are ready for a hypothesis test? Well there are tons of tools you can use to help you plan for power. In this workshop we’ll demonstrate the use of statpsych, a package for R by Doug Bonett. Why? Because statpsych is easy to use, comprehensive, has a consistent and well-documented set of functions, and has been extensively validated.\nLet’s continue our neurogenesis example. Suppose from previous research you do know a good bit about neurogenesis under control conditions: your lab has typically found about 3,500 neurons labelled within 2 hours of BRDU injection, with a standard deviation of 500. Furthermore, from previous research on neurogenesis you believe that stress will alter neurogenesis by a substantial amount, at least 700 neurons –that’s more than 1 standard deviation. Note that, for now we said “a change of at least”… that’s a non-directional hypothesis; we’ll start with this vague hypothesis and then switch to a directional hypothesis in a moment.\nWe need two additional inputs: stringency (alpha) and desired power. We’ll pick a traditional stringency (.05) and we’ll shoot for 90% power. You’ll often see 80% used as a convention, but who wants to let 20% of their true hypotheses fail to garner support? If the experiment will require considerable time and resources and is worth doing, then it is probably worth doing with a relatively high rate of power.)\nWe can put all this together and find our needed sample-size using the size.test.mean2 function in statpsych. This function, along with all other functions in statpsych, is documented here: https://dgbonett.github.io/statpsych/reference/index.html\n\nif (!require(\"statpsych\")) install.packages(\"statpsych\")\n\nLoading required package: statpsych\n\n# Get sample size for 90% power for a two-group hypothesis test of at least 700-neuron change \n#  with an assay with typical standard deviaiton of 500 neurons.  The test will be conducted\n#  with an alpha of .05.  We'll plan for equal sample-sizes in both groups.\nstatpsych::size.test.mean2(\n  alpha = 0.05,\n  pow = 0.90,\n  var = 500^2,     # Typical sd in our lab is 500 neurons; here we input variance (sd^2)\n  es = 700,\n  R = 1            # ratio of n1/n2; here we entered 1 for equal group sizes\n)\n\n n1 n2\n 12 12\n\n\nAccording to these calculations, we need n = 12 per group (24 animals in total) to conduct a well-powered test of our hypothesis. This is a good bit more than is typically used in neurogenesis research… but that’s a reflection of poor prior practice, not bad planning on our part.\nIf you are really ready for a hypothesis test then you almost certainly have a directional hypothesis. That’s a good thing, because that will reduce our sample-size needs relative to a non-direcitonal hypothesis. There is a cost, though: by making a directional hypothesis you are calling your shot. That is, you are committing to conducting the test only if the effect is in the predicted direction – otherwise it is a non-significant finding even if it would have been significant in the other direction. By making that commitment, you can get your desired power with less resources. Clearly, though, it would be best to document that commitment; a public pre-registration would be ideal. Unfortunately, abuse of directional tests has led to suspicion that they reflect p hacking–that’s a shame because if we used hypothesis testing for testing actual hypotheses we would almost always be conducting direcitonal effects–it is actually non-directional hypotheses that clue us to the fact that the researcher doesn’t seem to have any clear idea of what they’re predicing.\nAnyway, how do we plan for a directional hypothesis? Some tools have this as a specific option, but in general what you do is double the alpha used in your input. That is, for a .05 directional test, you can use .10 in a non-directional tool. Here’s what we’d get with statpsych:\n\nif (!require(\"statpsych\")) install.packages(\"statpsych\")\n\n# Get sample size for 90% power for a two-group hypothesis test of at least 700-neuron change \n#  with an assay with typical standard deviaiton of 500 neurons.  The test will be conducted\n#  with an alpha of .05.  We'll plan for equal sample-sizes in both groups.\nstatpsych::size.test.mean2(\n  alpha = 0.05 * 2,  # Double alpha for directional test\n  pow = 0.90,\n  var = 500^2,     # Typical sd in our lab is 500 neurons; here we input variance (sd^2)\n  es = 700,\n  R = 1            # ratio of n1/n2; here we entered 1 for equal group sizes\n)\n\n n1 n2\n 10 10\n\n\nNice! With a directional effect we can get by with n = 10/group or 20 animals overall. That’s a resource saving of 20%!",
    "crumbs": [
      "Course",
      "Three Approaches",
      "Planning for Power"
    ]
  },
  {
    "objectID": "Planning for Power.html#important-considerations-when-planning-for-power",
    "href": "Planning for Power.html#important-considerations-when-planning-for-power",
    "title": "Planning for Power",
    "section": "Important Considerations When Planning for Power",
    "text": "Important Considerations When Planning for Power\n\nWhat if your inputs are off? That, is what if variation is 20% higher than you expected? What if the effect is 20% weaker than you expected? Or 50%? The best practice is to explore a variety of inputs and judiciously choose a sample size. Sample-size needs can be much larger than you might be used to. Be sure to check out the section on optimization for some tips on how to deal with this.\nDoes your sample-size plan matches your research question. It sounds obvious, but you need to make sure you are planning for power for the analysis that answers your research quesiton. Note that with hypothesis tests that can sometimes be confusing. For example, suppose you test the effects of both stress (high/low) and sex (male/female) on neurogensis. You will probably want to test if stress affects neurogenesis in male mice. And you will probably want ot test if stress affects neurogenesis in female mice. But most importantly, you will probably want to know if there is a sex difference in the impact of stress (an interaction). In that case, you need to make sure your sample-size plan is for this interaction, which typically has considerably higher sample-size needs than either simple effect.\nWill you conduct multiple tests? When you will conduct multiple tests your risk of including a false-positive. You thus need to make a sample size plan that includes the increase needs for when adjusting for multiple comparisons. This can become complicated, and sometimes can only be solved through simulation. On the other hand, if you are using hypothesis testing only to test well-formed, quantitative hypotheses you may find yourself with only a few focal hypotheses to test in any given study.\nDo you have non-independent/hierarchical data? Hierarchical data (e.g. multiple cells recorded from the each animal in each condition) violates the non-independence assumed in most statistical tests. You will need to make sure you have a porper analysis strategy (e.g. sufficient summary statistics approach) and a power plan that matches.",
    "crumbs": [
      "Course",
      "Three Approaches",
      "Planning for Power"
    ]
  },
  {
    "objectID": "Planning for Power.html#planning-for-power-for-other-designs",
    "href": "Planning for Power.html#planning-for-power-for-other-designs",
    "title": "Planning for Power",
    "section": "Planning for Power for Other Designs",
    "text": "Planning for Power for Other Designs\nstatpsych has a wide range of functions for planning for power for simple designs (https://dgbonett.github.io/statpsych/reference/index.html). These include:\n\n\n\nsize.test.cor()\n\nSample size for a test of a Pearson or partial correlation\n\n\n\nsize.test.cor2()\n\nSample size for a test of equal Pearson or partial correlation in a 2-group design\n\n\n\nsize.test.lc.ancova()\n\nSample size for a mean linear contrast test in an ANCOVA\n\n\n\nsize.test.lc.mean.bs()\n\nSample size for a test of a between-subjects mean linear contrast\n\n\n\nsize.test.lc.mean.ws()\n\nSample size for a test of a within-subjects mean linear contrast\n\n\n\nsize.test.lc.prop.bs()\n\nSample size for a test of between-subjects proportion linear contrast\n\n\n\nsize.test.mann()\n\nSample size for a Mann-Whitney test\n\n\n\nsize.test.mean.ps()\n\nSample size for a test of a paired-samples mean difference\n\n\n\nsize.test.mean()\n\nSample size for a test of a mean\n\n\n\nsize.test.mean2()\n\nSample size for a test of a 2-group mean difference\n\n\n\nsize.test.prop.ps()\n\nSample size for a test of a paired-samples proportion difference\n\n\n\nsize.test.prop()\n\nSample size for a test of a single proportion\n\n\n\nsize.test.prop2()\n\nSample size for a test of a 2-group proportion difference\n\n\n\n\nOne thing you’ll notice that’s missing is interactions for complex designs – these are currently not available in statpsych. There are a number of good tools for more complex designs; one of http://www.intxpower.com/ and this companion paper (Sommet et al. 2023).",
    "crumbs": [
      "Course",
      "Three Approaches",
      "Planning for Power"
    ]
  },
  {
    "objectID": "posts/statpsych-for-sample-size-planning/index.html",
    "href": "posts/statpsych-for-sample-size-planning/index.html",
    "title": "statpsych for Sample-Size Planning",
    "section": "",
    "text": "One great tool for sample-size planning is the statpsych package by Doug Bonett.\nThere are loads and loads of goodies in statpsych, and the documentation is excellent and authoritative.\nHere, for example, is how you can find the sample-size needed to obtain a desired level of power for a predicted effect in a 2-group design\n\n# If you don't have statpsych installed, install it!\nif (!require(\"statpsych\")) install.packages(\"statpsych\")\n\nLoading required package: statpsych\n\n# size.test.mean2 gives power for the mean difference in a 2-group design\n# parameters are alpha level, desired power, average within-group variance, effect size, and ratio of group1 to group2 sample sizes\n# Full documentation is at: https://dgbonett.github.io/statpsych/reference/size.test.mean2.html\n# In this example, we have \n#  * an alpha of .05, \n#  * desired power of .95, \n#  * expected average variance of 100 (sd_avg = 10)\n#  * an predicted effect size of 10\n#  * and equal sample-sizes in both groups (ratio of 1 between n1 and n2)\n# The output shows that we need n = 27 per group.\nstatpsych::size.test.mean2(.05, .95, 100, 10, 1) \n\n n1 n2\n 27 27\n\n# We can easiy investigate other effect sizes, power levels, etc.  For example:\n#  Here we explore effect sizes of 5, 10, and 20 while keeping\n#  all other parameters constant\nfor(e_size in c(5, 10, 20)){\n  print(\n    paste(\n      \"For effect size of\", e_size,\n      \"need sample size of\", \n      paste(statpsych::size.test.mean2(.05, .95, 100, e_size, 1), collapse = \", \")\n    )\n  )\n  \n}\n\n[1] \"For effect size of 5 need sample size of 105, 105\"\n[1] \"For effect size of 10 need sample size of 27, 27\"\n[1] \"For effect size of 20 need sample size of 8, 8\""
  },
  {
    "objectID": "Resources.html",
    "href": "Resources.html",
    "title": "Resources",
    "section": "",
    "text": "Here are some resources I found useful for developing this workshop. I’ll do my best to keep it updated. If you come across a resource you feel is helpful, submit it on the GitHub discussion board for this workshop (https://github.com/rcalinjageman/esci/discussions) and I’ll add it to this list and feature it in a blog post.\n\nGuidelines and Regulations Related to Sample-Size Planning\nOn important reason to plan your sample-size in advance is stakeholders in the life sciences are increasingly requiring evidence that sample-sizes are adequate\n\nNIH\n\nAs of 2016, NIH has adopted a new initiative on Rigor and Reproducibility that stress evaluation of project proposals for their ability to produce robust and unbiased results.\nIn explaining this new policy, sample-size planning was listed as a way to help meet this new evaluation criterion. See the NIH blog post here:\n\nReporting Guidelines - NIH also helped organize a set of principles for the reporting of pre-clinical research; these guidelines were endorsed by a wide variety of journals and professional societies.\n\nHere are the NIH guidelines. The guidelines related to transparency stipulates that authors should explain their sample-size determinations.\nMany journals either already enforced these guidelines are have updated their author instructions to do so.\n\nNature Neuroscience announced updated standards in 2013 editorial and released a reporting checklist authors should complete on submission that requires sample-size planning.\nJournal of Neuroscience has issued updated author guidelines as of March of 2017 that asks for sample-size justification. The updated guidelines are here.\n\n\nEthical guidelines - the American Stasitical Association has put forth ethical guidelines for those who regularly use statistics. These enjoin statisticians to collect neither too much nor too little data (as both are ethically problematic). The guidelines are online here.\n\n\n\nBackground Reading\n\nFor neuroscientists, the most lucid explanation of the importance of sample-size planning is a recent commentary by Yarkoni (2009). This paper explains why small sample sizes are problematic even if results are statistically significant.\n\nYarkoni, T. (2009). Big Correlations in Little Studies. Perspectives on Psychological Science, 4(3), 294–298. https://doi.org/10.1111/j.1745-6924.2009.01127.x\n\nThe fact that sample sizes are too small in the neurosciences is now well-documented. Here are three eye-opening readings:\n\nButton, K. S., Ioannidis, J. P. a., Mokrysz, C., Nosek, B. a., Flint, J., Robinson, E. S. J., & Munafò, M. R. (2013). Power failure: why small sample size undermines the reliability of neuroscience. Nature Reviews. Neuroscience, 14(5), 365–76. https://doi.org/10.1038/nrn3475\nSzucs, D., & Ioannidis, J. P. A. (2017). When Null Hypothesis Significance Testing Is Unsuitable for Research: A Reassessment. Frontiers in Human Neuroscience, 11. https://doi.org/10.3389/fnhum.2017.00390\nCarniero et al. (currently a pre-print). Effect sizes and statistical power in the rodent fear conditioning liturature: A systematic review. http://dx.doi.org/10.1101/116202\n\nRun-and-check is a common practice, but not a good one. Here’s a modern source and a classic source:\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological Science, 22(11), 1359–66. https://doi.org/10.1177/0956797611417632\nAnscombe, F. J. (1954). Fixed-Sample-Size Analysis of Sequential Observations. Biometrics, 10(1), 89. https://doi.org/10.2307/3001665\n\nUnderstanding effect sizes can be challenging. Here’s an excellent source that makes everything clear:\n\nLakens, D. (2013). Calculating and reporting effect sizes to facilitate cumulative science: A practical primer for t-tests and ANOVAs. Frontiers in Psychology, 4(NOV), 1–12. https://doi.org/10.3389/fpsyg.2013.00863\n\nFinally, here are some other sources that are well-worth checking out:\n\nIoannidis, J. P. A. (2005). Why Most Published Research Findings Are False. PLoS Medicine, 2(8), e124. https://doi.org/10.1371/journal.pmed.0020124\nCumming, G. (2008). Replication and p intervals. Perspectives on Psychological Science, 3(4), 286–300. https://doi.org/10.1111/j.1745-6924.2008.00079.x\n\n\n\n\nPlanning for Power\n\nDealing with Uncertainty and Publication Bias\nThere are already lots of sources and tools for planning for power. Although the approach is easy to adopt, it is important to remember that:\n\nEffect sizes in the published literature may be biased, and\nEffect sizes estimated from small samples are often uncertain.\n\nTherefore, it is a good idea to hedge your sample-size estimatesagainst both bias and uncertainty.\nKen Kelley’s group has an approach that does this:\n\nThe R package of tools is called BUCSS– Bias and Unertainty Corrected Sample Sizes: https://cran.r-project.org/web/packages/BUCSS/index.html\nThe website designingexperiments.com has web apps that allow you to plan for power in this careful way without having to learn R. Scroll to the bottom of the page of webapps to select your design and load the appropriate web app.\nA paper describing this approach is here: Anderson, S. F., Kelley, K., & Maxwell, S. E. (2017). Sample-Size Planning for More Accurate Statistical Power: A Method Adjusting Sample Effect Sizes for Publication Bias and Uncertainty. Psychological Science, 95679761772372. https://doi.org/10.1177/0956797617723724\n\n\n\nSequential Testing\nIf you are going to use planning for power, sequential testing can be more efficient, especially in the exploratory phase of research. Lakens offers an excellent tutorial:\n\nLakens, D. (2014). Performing high-powered studies efficiently with sequential analyses. European Journal of Social Psychology, 44(7), 701–710. https://doi.org/10.1002/ejsp.2023\n\n\n\n\nPlanning for Precision\nPlanning for precision is also known as Accuracy in Parameter Estimatation (AIPE). In this approach, the researcher’s goal is to control the noise/error in the result–a sample size is selected that will give a reasonable margin of error relative to the research question and the scale of measurement.\nOne set of readings and tools are from Geoff Cumming and his collaborators:\n\nesci - Is a free set of online tools for understanding as well as an R package for data analysis. Here is a link to planning-for-precision functions in the online tools included in esci: https://esci.thenewstatistics.com/esci-precision.html#tab-1\nCumming has two books which have coverage on planning for precision. Both are readable and accessible to a general scientific audience.\n\nThis book is for those already well-versed in p values: Cumming, G. (2011). Understanding the new statistics: Effect sizes, confidence intervals, and meta-analysis. New York: Routledge.\nThis book is for undergraduates learning stats, but has a bit more updated material on planning for precision: Cumming, G., & Calin-Jageman, R. J. (2024, 2nd edition). Introduction to the new statistics: Estimation, open science, and beyond. New York: Routledge.\n\n\nAnother set of readings and tools are from Ken Kelley and his collaborators.\n\nMBESS - Is a free R package that contains many different useful functions. Among those are functions for planning for precision (which Kelley terms AIPE). The functions in MBESS are complex, but they can be used for a wide variety of experimental designs. https://cran.r-project.org/web/packages/MBESS/index.html\nDesigningExperiments.com has free web applications that allow planning for precision with the functions embedded into MBESS. This makes them easier to use. Given that they can handle complex designs, it is not surprising that the learning curve is a bit steep even for the web application.\nKelley and his colleagues have a number of papers and sources on the AIPE approach. Also reccomended is his excellent book Designing Experiments and Analyzing Data.\n\nMaxwell, S. E., Delaney, H. D., & Kelley, K. (2018). Designing Experiments and Analyzing Data: A Model Comparison Perspective (3rd ed.). New York: Routledge.\nMaxwell, S. E., Kelley, K., & Rausch, J. R. (2008). Sample Size Planning for Statistical Power and Accuracy in Parameter Estimation. Annual Review of Psychology, 59(1), 537–563. https://doi.org/10.1146/annurev.psych.59.103006.093735\nKelley, K. (2007). Sample size planning for the coefficient of variation from the accuracy in parameter estimation approach. Behav Res Meth, 39(4), 755–766. https://doi.org/10.3758/BF03192966\nKelley, K., & Maxwell, S. E. (2003). Sample Size for Multiple Regression: Obtaining Regression Coefficients That Are Accurate, Not Simply Significant. Psychological Methods, 8(3), 305–321. https://doi.org/10.1037/1082-989X.8.3.305\nKelley, K., & Maxwell, S. E. (2003). Sample Size for Multiple Regression: Obtaining Regression Coefficients That Are Accurate, Not Simply Significant. Psychological Methods, 8(3), 305–321. https://doi.org/10.1037/1082-989X.8.3.305\n\n\nSAS has tools that enable planning for precision:\n\nThe usage guide is here.\nSAS also provides some sample cases, such as this one.\n\nPlanning for precision is also perfect for Bayesians. John Kruschke has written a book and provides excellent tools for what her terms the Bayesian New Statistics:\n\nKruschke, J (2014). Doing Bayesian Data Analysis. Eslevier. https://www.elsevier.com/books/doing-bayesian-data-analysis/kruschke/978-0-12-405888-0\nKruschke, J. K., & Liddell, T. M. (2017). The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective. Psychonomic Bulletin & Review. https://doi.org/10.3758/s13423-016-1221-4\n\n\n\nOther Approaches to Planning\nThere are lots of other good ways to plan your studies..I couldn’t cover them all. Here are three noteworthy papers and approaches.\n\nPlanning for Evidence - If you like Bayesian hypothesis testing, a very good approach is to plan for evidence rather than sample size. That is, you can commit to collecting data until you achieve clear evidence for your hypothesis or for the null hypothesis. It sounds scary because data collection is therefore open-ended, yet simulations show this can actually be a very efficient approach.\n\nSchönbrodt, F. D., & Wagenmakers, E.-J. (2017). Bayes factor design analysis: Planning for compelling evidence. Psychonomic Bulletin & Review, 1–16. https://doi.org/10.3758/s13423-017-1230-y\n\n\nPlanning for Stability - not too different from planning for precision, this approach is to select a sample-size that will provide enough information that subsequent replications will achieve similar results within a set level of similarity.\n\nLakens, D., & Evers, E. R. K. (2014). Sailing From the Seas of Chaos Into the Corridor of Stability: Practical Recommendations to Increase the Informational Value of Studies. Perspectives on Psychological Science, 9(3), 278–292. https://doi.org/10.1177/1745691614528520\nGelman’s approach:\n\nGelman, A., & Carlin, J. (2014). Beyond power calculations: Assessing Type S (sign) and Type M (magnitude) errors. https://doi.org/10.1177/1745691614551642",
    "crumbs": [
      "Course",
      "Resources"
    ]
  },
  {
    "objectID": "What Not To Do.html",
    "href": "What Not To Do.html",
    "title": "How Not to Get Your Sample Size",
    "section": "",
    "text": "The video above walks through some common but poor sample-size planning practices: run-and-check (backing into a sample-size by chasing statistical significance) and uncritically adopting previous sample sizes.\nIn the explorations below you can dig into why run-and-check is so bad, and you can also explore the suprising fact that p &lt; .05 does not mean you have an adequate sample size.",
    "crumbs": [
      "Course",
      "What Not To Do"
    ]
  },
  {
    "objectID": "What Not To Do.html#exploration-dont-run-and-check",
    "href": "What Not To Do.html#exploration-dont-run-and-check",
    "title": "How Not to Get Your Sample Size",
    "section": "Exploration: Don’t Run-and-Check!",
    "text": "Exploration: Don’t Run-and-Check!\nA common approach to sample-size determination is Run-and-Check: you run a small batch of samples, check for significance, and then keep adding samples until you either get what you want or run out of time/resources. Sometimes run-and-check is conducted over people/labs – keep assigning the same project to different trainees until someone with ‘good hands’ gets it to work (sometimes that really is good hands, but it can also easily be capitalization chance!).\nLet’s examine why run-and-check is so dangerous to good science. We’ll simulate data for a two-group experiment, with the simulation set so that there is no true effect in the population. We’ll start with n = 3/group, then check. If the results are significant, we stop, otherwise we add 1 sample/group and check again, and so on, to a limit of n = 30 group. In this scenario, any statistically significant finding is a false positive. We’ll run 10,000 simulations and check the false-positive rate.\nThe code for the simulation is below. Before you scroll down to its output, what is your guess for the false positive rate for this run-and-check approach?\n\n# If needed, install needed libraries\nif (!require(\"statpsych\")) install.packages(\"statpsych\")\nif (!require(\"ggplot2\")) install.packages(\"ggplot2\")\nif (!require(\"gganimate\")) install.packages(\"gganimate\")\nif (!require(\"gifski\")) install.packages(\"gifski\")\n\n\n# Load needed libraries\nlibrary(statpsych)\nlibrary(ggplot2)\nlibrary(gganimate)\n\n\n# Simulation parameters\nn_initial &lt;- 3\nn_add_per_round &lt;- 1\nn_to_give_up &lt;- 30\ntrue_effect_size &lt;- 0\ntotal_sims &lt;- 1000\n\n# Initialize variables for results\nfalse_positives &lt;- 0\nrandc_res &lt;- data.frame(p = NA, n = NA, sample = NA, eventually_significant = NA)\nresults_row &lt;- 0\n\n# simulation \nfor (i in 1:total_sims) {\n  \n  # simulate data at initial sample size for both groups and do t.test\n  n_current &lt;- n_initial\n  g1 &lt;- rnorm(n_current, 0, 1)\n  g2 &lt;- rnorm(n_current, 0 + true_effect_size, 1)\n  res &lt;- t.test(g1, g2)$p.value\n  results_row &lt;- results_row + 1\n  \n  # store the results for plotting\n  randc_res[results_row, ] &lt;- c(\n    res,\n    n_current,\n    i,\n    FALSE\n  )\n  \n  # if not significant and not at n_to_give_up yet, keep going\n  while (res &gt;= .05 & n_current &lt; n_to_give_up) {\n    g1 &lt;- c(g1, rnorm(n_add_per_round, 0, 1))\n    g2 &lt;- c(g2, rnorm(n_add_per_round, 0 + true_effect_size, 1))\n    n_current &lt;- n_current + n_add_per_round\n    results_row &lt;- results_row + 1\n    res &lt;- t.test(g1, g2)$p.value\n    \n    randc_res[results_row, ] &lt;- c(\n      res,\n      n_current,\n      i,\n      FALSE\n    )\n  }\n  \n  # If the final result is significnt, that's a false positive (assuming true_effect_size == 0)\n  if (res &lt; .05) {\n    false_positives &lt;- false_positives + 1\n    randc_res[randc_res$sample == i, ]$eventually_significant &lt;- TRUE\n  }\n  \n}\n\n\nprint(\n  paste(\n    \"Simulated\", total_sims, \n    \"two-group studies with a true mean difference of\", true_effect_size,\n    \"where sample sizes started off with\", n_initial, \"/group\",\n    \"and if not significant added\", n_add_per_round, \"/group and re-checked,\",\n    \"up to significance or a max sample size of\", n_to_give_up, \".\"\n  )\n)\nprint(\"Proportion of significant findings\")\nprint(false_positives / total_sims)\n\n\nSimulation Results: False-Positive Rate\nThe code simulated 1000 two-group studies with a true mean difference 0 where sample sizes started off with 3/group and if not significant added 1/group up to significance or a max sample size of 30.\nUnder this scenario, the proportion of false positives is: 23.8%.\nThis scenario is a bit extreme, but it makes it clear that run-and-check is not a good method for determining sample size.\n\n\nSimulation Results: The Deceptive Dance of the p Value\nTo make this even more clear, we’re going to plot the p values as sample sizes are added, cycling through the first 10 simulations(Figure 1). What you’ll notice is that the p values “feel” like they are following trajectories, swining higher or lower. This can give the researcher using run-and-check the feeling that they’re on to something, and that they are justified adding more samples, or worse, adjusting their analyses to coax the p value below .05.\n\n\nCode\nrandc_res$animate_frame &lt;- 1:nrow(randc_res)\nrandc_res$eventually_significant &lt;- as.factor(randc_res$eventually_significant)\nrandc_res$sample_as_factor &lt;- as.factor(randc_res$sample)\n\npdance_plot &lt;- ggplot(data = randc_res[randc_res$sample &lt; 5 , ], aes(x = n, y = p, group = sample, colour = eventually_significant))\npdance_plot &lt;- pdance_plot + ylab(\"Obtained p value\")\npdance_plot &lt;- pdance_plot + xlab(\"Sample size\")\npdance_plot &lt;- pdance_plot + geom_point(size = 3)\npdance_plot &lt;- pdance_plot + theme_classic() + theme(legend.position = \"none\")\npdance_plot &lt;- pdance_plot + geom_hline(yintercept = 0.05, linetype = \"dotted\")\npdance_plot &lt;- pdance_plot + scale_colour_manual(values = c(\"1\" = \"red\", \"0\" = \"dodgerblue1\"))\npdance_plot &lt;- pdance_plot + ylim(c(0, 1))\npdance_plot &lt;- pdance_plot + xlim(c(n_initial, n_to_give_up))\npdance_plot &lt;- pdance_plot + transition_reveal(animate_frame, keep_last = FALSE)\nanimate(pdance_plot, fps = 2, renderer = gifski_renderer(\"run_and_check.gif\"))\n\n\n\n\n\n\n\n\nFigure 1: Evolution of p values as samples are added but no true effect\n\n\n\n\n\nThus, it’s not just the instinsic false-positive rate of run-and-check that is dangerous but also the false impression it can give that might license analytic flexibility towards erroneous results.",
    "crumbs": [
      "Course",
      "What Not To Do"
    ]
  }
]